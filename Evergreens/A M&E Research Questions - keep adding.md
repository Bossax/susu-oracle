---
type: idea
status:
  - archived
tags: []
created: 2025-11-20
AI_prompt: false
---
Update to 
[[Note Thailand BTR Adaptation Project Proposal]]

After researching Thai government's M&E system
[[กพร - กรอบการประเมินผลการปฏิบัติราชการของส่วนราชการ]]
[[Thailand governance diagram.canvas|Thailand governance]]
[[สำนักงบประมาณ - การประเมินผลแผนบูรณาการ]]
[[สำนักงบประมาณ - การประเมินผลหน่วยงานรับทุน]]
# M&E project scope 

Thailand has established a comprehensive performance evaluation as part of the core system of government administration. The M&E system links line agency's activities to government's policies via sets of KPIs. 

Top level requirements for setting the KPIs
1. National Economic and Social Development Plan -> NEDSC
2. Master Plans such as water management strategic plan-> line ministries/ committee
3. Prime minister's mandates -> Government
4. Cabinet's orders -> Government

The goals of these plans are translated into Strategic KPI,  Joint KPI, and Function KPI

- Strategic KPIs are set using a *committee mechanism* with OPSDC as the secretariat
- Joint KPIs are set through a co-creation process led by OPSDC
- Function KPIs are the most static and least tampered by third parties (except the parliament)

Budget Bureau (BB) also has a set of KPIs to track and evaluate the performance of spending. The indicators are separate into
1. Integrative plans
2. Functional plans (budget receiving agencies)
BB stresses on impact indicators (ผลสัมภฤทธิ์). However, upon the review, these impact indicators are still not `impact indicators` in the sense of climate change adaptation; although, they are not project specific but agency-specific.

## Now, what is the goal of adaptation M&E?

Let's briefly check the M&E of international development projects
For international development agencies, these are key objectives of M&E systems
*Monitoring* is for
1. Project improvement
2. Accountability of the funders
3. Portfolio performance management
4. Impact measurement
5. Compliance
6. Tracking and Progress reporting

*Evaluation* is for
1. To ensure lessons are learned from existing programs
2. To improve development impact
3. To improve transparency and accountability
4. To provide evidence for policy makers
5. To pilot the effectiveness of innovative approaches
use information from Monitoring and other sources

However, the M&E systems n this content are more like Programme M&E.
### What scope could the adaptation M&E system cover?

#### NAP process focus
1. Monitoring - most countries start with monitoring to gather information of implementation and progress for *reporting*. 
2. NAP process evaluation - next step is to evaluate the NAP process. This is done by the designated agency similar to a third-party evaluator. The results are the
3. Evaluation at bigger and smaller scales
	1. Bigger scale such as country level resilience
	2. Smaller scales such as program level (of a master plan), initiative levels (within a region, province, city)
4. Learning process - integrate the evaluation results into decision making space. This is closely linked to the idea of [[Comprehensive Risk Management]] since it also provides the present status of residual risk, adaptive capacity, and vulnerability. 

#### Whole-society
1. Overall progress of implementing adaptation actions - this includes stock take actions from non-state actors like the private sectors and civil society


### Logical Framework and Theory of Change for adaptation planning

[[กพร - Office of the Public Sector Development Commission]] when setting the Joint KPIs, they are based on the *Value Chain* diagram of the issue; to see who must be involved in driving the change in that area.

NAP planning also needs the LogFrame and ToC for each sector to understand the linakge between the types of projects/plans and the desired outcome represented by the indicators

NAP has laid out key strategies to drive the progress in adaptation in the key sectors. Preliminary indicators at the sector level have been chosen to monitor and evaluate adaptation progress. However, the criteria and theoretical framework for choosing these indicators are unclear [[Analysis of TDRI work on NAP Indicators and Adaptation M&E Contribution]] and [[คู่มือการติดตามและประเมินผล Climate Change Adaptation โดย DCCE]]

Currently, there are no action plans that really states what key sectoral initiatives need to be executed within a short-, to, medium - time frame such as 2-5 years. There are no LogFrame or Theory of Change of NAP strategies that are publicly available.  This is the current challenge(which is huge) for adaptation planning. More about implementing the adaptation initiatives. in later section. 

# Scope of adaptation M&E

The definition and scope of adaptation M&E in this project focuses on the details of  monitoring of the **NAP process** and touches on the **conceptual framework of evaluation of the NAP process**.

So, we focus on sectoral level and national level.

## Monitoring of the NAP process
1. Streamlining data reporting of ministerial focal points
	The ad-hoc data collection needs to be standardized. Data templates and formatting will be proposed in this project. We also need to categorize the reported indicators into institutionalized reporting mandates and additional data collection. Solutions to streamline the reporting will be proposed. 
2. Development of the indicator standards. This will be the base for discussion of what data collection programs need to be created to support the work of the ministerial focal points (and standardization of the indicator definitions, data collection, and processing). The preliminary indicator set can serve as groundwork for improvement. This project will apply sound theoretical framework to this set to assess and comment on their suitability (and practicality)

## Assessment of the current indicator sets
Theoretical work is also part of this task. The existing sectoral indicators need dissecting. Similar to administrative M&E structure, the NAP sectoral indicators need a structure to group which indicators are for monitoring and which indicators are for evaluation. We will proposed the structure in this project and point out gaps in monitoring indicators and evaluation framework (and maybe basic evaluation indicators)


# As of 4 Sep 2025
after reading [[Analysis of TDRI work on NAP Indicators and Adaptation M&E Contribution]] and [[คู่มือการติดตามและประเมินผล Climate Change Adaptation โดย DCCE]]
I come up with a list of points for consideration for M&E indicator selections
1. Aggregation
	1. High level national data system
	2. Place specific non-aggregable
2. Local level indicator sets
	1. complement high-level indicator
3. Qualitative data
	1. Survey 
	2. Sentiment analysis
4. Baseline values
	1. Attainable
	2. Estimated
	3. Unattainable
5. Data collection process
	1. methodology
	2. standard

# Challenges in implementing adaptation actions

Say the researchers have done projects to find adaptation scenarios for the key sectors of Thailand's economy, we still face challenges from the current bureaucratic and administrative structures. The ministries and line departments are function based; they are notorious for performing siloed work which make driving national strategy, even one about economic development, very difficult.

The series of notes about government performance evaluation depict the frameworks, mechanisms, and workflow of this routine. 

In this project, we need to leverage the monitoring routines performed by all line agencies as required by law. This way, adaptation monitoring for tracking "NAP" will not be a separate process, but rather sub-set of the which would offload much of administrative burden from DCCE. They just need to connect data pipelines with the Office of the Public Sector Development Commission who is in charge of government performance evaluation. 

The next step would be, list the variables that are additional to the performance evaluation routines and needed to be reported by the line agencies. What could be the strategies for getting this data?
a) ask Office of the Public Sector Development Commission to integrate these varaiables into monitoring indicators?
b) DCCE creates a separate platforms to track project progress and the changes in the indicators?

Maybe the question would be are these indicators project specific? or they are at higher levels than the project levels?

The last thing would be the evaluation. Evaluation could be just benchmarking the indicators against the target values or collecting additional data to track the changes in the system (sector or initiative levels for example) 


[[Key questions for M&E framework design]]
